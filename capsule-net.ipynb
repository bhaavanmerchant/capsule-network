{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(batch_size, is_training=True):\n",
    "    path = os.path.join('data', 'mnist')\n",
    "    if is_training:\n",
    "        fd = open(os.path.join(path, 'train-images-idx3-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        trainX = loaded[16:].reshape((60000, 28, 28, 1)).astype(np.float32)\n",
    "\n",
    "        fd = open(os.path.join(path, 'train-labels-idx1-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        trainY = loaded[8:].reshape((60000)).astype(np.int32)\n",
    "\n",
    "        trX = trainX[:55000] / 255.\n",
    "        trY = trainY[:55000]\n",
    "\n",
    "        valX = trainX[55000:, ] / 255.\n",
    "        valY = trainY[55000:]\n",
    "\n",
    "        num_tr_batch = 55000 // batch_size\n",
    "        num_val_batch = 5000 // batch_size\n",
    "\n",
    "        return trX, trY, num_tr_batch, valX, valY, num_val_batch\n",
    "    else:\n",
    "        fd = open(os.path.join(path, 't10k-images-idx3-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        teX = loaded[16:].reshape((10000, 28, 28, 1)).astype(np.float)\n",
    "\n",
    "        fd = open(os.path.join(path, 't10k-labels-idx1-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        teY = loaded[8:].reshape((10000)).astype(np.int32)\n",
    "\n",
    "        num_te_batch = 10000 // batch_size\n",
    "        return teX / 255., teY, num_te_batch\n",
    "\n",
    "\n",
    "def load_fashion_mnist(batch_size, is_training=True):\n",
    "    path = os.path.join('data', 'fashion-mnist')\n",
    "    if is_training:\n",
    "        fd = open(os.path.join(path, 'train-images-idx3-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        trainX = loaded[16:].reshape((60000, 28, 28, 1)).astype(np.float32)\n",
    "\n",
    "        fd = open(os.path.join(path, 'train-labels-idx1-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        trainY = loaded[8:].reshape((60000)).astype(np.int32)\n",
    "\n",
    "        trX = trainX[:55000] / 255.\n",
    "        trY = trainY[:55000]\n",
    "\n",
    "        valX = trainX[55000:, ] / 255.\n",
    "        valY = trainY[55000:]\n",
    "\n",
    "        num_tr_batch = 55000 // batch_size\n",
    "        num_val_batch = 5000 // batch_size\n",
    "\n",
    "        return trX, trY, num_tr_batch, valX, valY, num_val_batch\n",
    "    else:\n",
    "        fd = open(os.path.join(path, 't10k-images-idx3-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        teX = loaded[16:].reshape((10000, 28, 28, 1)).astype(np.float)\n",
    "\n",
    "        fd = open(os.path.join(path, 't10k-labels-idx1-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        teY = loaded[8:].reshape((10000)).astype(np.int32)\n",
    "\n",
    "        num_te_batch = 10000 // batch_size\n",
    "        return teX / 255., teY, num_te_batch\n",
    "\n",
    "\n",
    "def load_data(dataset, batch_size, is_training=True, one_hot=False):\n",
    "    if dataset == 'mnist':\n",
    "        return load_mnist(batch_size, is_training)\n",
    "    elif dataset == 'fashion-mnist':\n",
    "        return load_fashion_mnist(batch_size, is_training)\n",
    "    else:\n",
    "        raise Exception('Invalid dataset, please check the name of dataset:', dataset)\n",
    "\n",
    "\n",
    "def get_batch_data(dataset, batch_size, num_threads):\n",
    "    if dataset == 'mnist':\n",
    "        trX, trY, num_tr_batch, valX, valY, num_val_batch = load_mnist(batch_size, is_training=True)\n",
    "    elif dataset == 'fashion-mnist':\n",
    "        trX, trY, num_tr_batch, valX, valY, num_val_batch = load_fashion_mnist(batch_size, is_training=True)\n",
    "    data_queues = tf.train.slice_input_producer([trX, trY])\n",
    "    X, Y = tf.train.shuffle_batch(data_queues, num_threads=num_threads,\n",
    "                                  batch_size=batch_size,\n",
    "                                  capacity=batch_size * 64,\n",
    "                                  min_after_dequeue=batch_size * 32,\n",
    "                                  allow_smaller_final_batch=False)\n",
    "\n",
    "    return(X, Y)\n",
    "\n",
    "\n",
    "def save_images(imgs, size, path):\n",
    "    '''\n",
    "    Args:\n",
    "        imgs: [batch_size, image_height, image_width]\n",
    "        size: a list with tow int elements, [image_height, image_width]\n",
    "        path: the path to save images\n",
    "    '''\n",
    "    imgs = (imgs + 1.) / 2  # inverse_transform\n",
    "    return(scipy.misc.imsave(path, mergeImgs(imgs, size)))\n",
    "\n",
    "\n",
    "def mergeImgs(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    imgs = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        imgs[j * h:j * h + h, i * w:i * w + w, :] = image\n",
    "\n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "\n",
    "############################\n",
    "#    hyper parameters      #\n",
    "############################\n",
    "\n",
    "# For separate margin loss\n",
    "flags.DEFINE_float('m_plus', 0.9, 'the parameter of m plus')\n",
    "flags.DEFINE_float('m_minus', 0.1, 'the parameter of m minus')\n",
    "flags.DEFINE_float('lambda_val', 0.5, 'down weight of the loss for absent digit classes')\n",
    "\n",
    "# for training\n",
    "flags.DEFINE_integer('batch_size', 128, 'batch size')\n",
    "flags.DEFINE_integer('epoch', 50, 'epoch')\n",
    "flags.DEFINE_integer('iter_routing', 3, 'number of iterations in routing algorithm')\n",
    "flags.DEFINE_boolean('mask_with_y', True, 'use the true label to mask out target capsule or not')\n",
    "\n",
    "flags.DEFINE_float('stddev', 0.01, 'stddev for W initializer')\n",
    "flags.DEFINE_float('regularization_scale', 0.392, 'regularization coefficient for reconstruction loss, default to 0.0005*784=0.392')\n",
    "\n",
    "\n",
    "############################\n",
    "#   environment setting    #\n",
    "############################\n",
    "flags.DEFINE_string('dataset', 'mnist', 'The name of dataset [mnist, fashion-mnist')\n",
    "flags.DEFINE_boolean('is_training', True, 'train or predict phase')\n",
    "flags.DEFINE_integer('num_threads', 8, 'number of threads of enqueueing exampls')\n",
    "flags.DEFINE_string('logdir', 'logdir', 'logs directory')\n",
    "flags.DEFINE_integer('train_sum_freq', 100, 'the frequency of saving train summary(step)')\n",
    "flags.DEFINE_integer('val_sum_freq', 500, 'the frequency of saving valuation summary(step)')\n",
    "flags.DEFINE_integer('save_freq', 3, 'the frequency of saving model(epoch)')\n",
    "flags.DEFINE_string('results', 'results', 'path for saving results')\n",
    "\n",
    "############################\n",
    "#   distributed setting    #\n",
    "############################\n",
    "flags.DEFINE_integer('num_gpu', 2, 'number of gpus for distributed training')\n",
    "flags.DEFINE_integer('batch_size_per_gpu', 128, 'batch size on 1 gpu')\n",
    "flags.DEFINE_integer('thread_per_gpu', 4, 'Number of preprocessing threads per tower.')\n",
    "\n",
    "cfg = tf.app.flags.FLAGS\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-9\n",
    "\n",
    "\n",
    "class CapsLayer(object):\n",
    "    ''' Capsule layer.\n",
    "    Args:\n",
    "        input: A 4-D tensor.\n",
    "        num_outputs: the number of capsule in this layer.\n",
    "        vec_len: integer, the length of the output vector of a capsule.\n",
    "        layer_type: string, one of 'FC' or \"CONV\", the type of this layer,\n",
    "            fully connected or convolution, for the future expansion capability\n",
    "        with_routing: boolean, this capsule is routing with the\n",
    "                      lower-level layer capsule.\n",
    "\n",
    "    Returns:\n",
    "        A 4-D tensor.\n",
    "    '''\n",
    "    def __init__(self, num_outputs, vec_len, with_routing=True, layer_type='FC'):\n",
    "        self.num_outputs = num_outputs\n",
    "        self.vec_len = vec_len\n",
    "        self.with_routing = with_routing\n",
    "        self.layer_type = layer_type\n",
    "\n",
    "    def __call__(self, input, kernel_size=None, stride=None):\n",
    "        '''\n",
    "        The parameters 'kernel_size' and 'stride' will be used while 'layer_type' equal 'CONV'\n",
    "        '''\n",
    "        if self.layer_type == 'CONV':\n",
    "            self.kernel_size = kernel_size\n",
    "            self.stride = stride\n",
    "\n",
    "            if not self.with_routing:\n",
    "                # the PrimaryCaps layer, a convolutional layer\n",
    "                # input: [batch_size, 20, 20, 256]\n",
    "                assert input.get_shape() == [cfg.batch_size, 20, 20, 256]\n",
    "\n",
    "                '''\n",
    "                # version 1, computational expensive\n",
    "                capsules = []\n",
    "                for i in range(self.vec_len):\n",
    "                    # each capsule i: [batch_size, 6, 6, 32]\n",
    "                    with tf.variable_scope('ConvUnit_' + str(i)):\n",
    "                        caps_i = tf.contrib.layers.conv2d(input, self.num_outputs,\n",
    "                                                          self.kernel_size, self.stride,\n",
    "                                                          padding=\"VALID\", activation_fn=None)\n",
    "                        caps_i = tf.reshape(caps_i, shape=(cfg.batch_size, -1, 1, 1))\n",
    "                        capsules.append(caps_i)\n",
    "                assert capsules[0].get_shape() == [cfg.batch_size, 1152, 1, 1]\n",
    "                capsules = tf.concat(capsules, axis=2)\n",
    "                '''\n",
    "\n",
    "                # version 2, equivalent to version 1 but higher computational\n",
    "                # efficiency.\n",
    "                # NOTE: I can't find out any words from the paper whether the\n",
    "                # PrimaryCap convolution does a ReLU activation or not before\n",
    "                # squashing function, but experiment show that using ReLU get a\n",
    "                # higher test accuracy. So, which one to use will be your choice\n",
    "                capsules = tf.contrib.layers.conv2d(input, self.num_outputs * self.vec_len,\n",
    "                                                    self.kernel_size, self.stride, padding=\"VALID\",\n",
    "                                                    activation_fn=tf.nn.relu)\n",
    "                # capsules = tf.contrib.layers.conv2d(input, self.num_outputs * self.vec_len,\n",
    "                #                                    self.kernel_size, self.stride,padding=\"VALID\",\n",
    "                #                                    activation_fn=None)\n",
    "                capsules = tf.reshape(capsules, (cfg.batch_size, -1, self.vec_len, 1))\n",
    "\n",
    "                # [batch_size, 1152, 8, 1]\n",
    "                capsules = squash(capsules)\n",
    "                assert capsules.get_shape() == [cfg.batch_size, 1152, 8, 1]\n",
    "                return(capsules)\n",
    "\n",
    "        if self.layer_type == 'FC':\n",
    "            if self.with_routing:\n",
    "                # the DigitCaps layer, a fully connected layer\n",
    "                # Reshape the input into [batch_size, 1152, 1, 8, 1]\n",
    "                self.input = tf.reshape(input, shape=(cfg.batch_size, -1, 1, input.shape[-2].value, 1))\n",
    "\n",
    "                with tf.variable_scope('routing'):\n",
    "                    # b_IJ: [batch_size, num_caps_l, num_caps_l_plus_1, 1, 1],\n",
    "                    # about the reason of using 'batch_size', see issue #21\n",
    "                    b_IJ = tf.constant(np.zeros([cfg.batch_size, input.shape[1].value, self.num_outputs, 1, 1], dtype=np.float32))\n",
    "                    capsules = routing(self.input, b_IJ)\n",
    "                    capsules = tf.squeeze(capsules, axis=1)\n",
    "\n",
    "            return(capsules)\n",
    "\n",
    "\n",
    "def routing(input, b_IJ):\n",
    "    ''' The routing algorithm.\n",
    "\n",
    "    Args:\n",
    "        input: A Tensor with [batch_size, num_caps_l=1152, 1, length(u_i)=8, 1]\n",
    "               shape, num_caps_l meaning the number of capsule in the layer l.\n",
    "    Returns:\n",
    "        A Tensor of shape [batch_size, num_caps_l_plus_1, length(v_j)=16, 1]\n",
    "        representing the vector output `v_j` in the layer l+1\n",
    "    Notes:\n",
    "        u_i represents the vector output of capsule i in the layer l, and\n",
    "        v_j the vector output of capsule j in the layer l+1.\n",
    "     '''\n",
    "\n",
    "    # W: [num_caps_i, num_caps_j, len_u_i, len_v_j]\n",
    "    W = tf.get_variable('Weight', shape=(1, 1152, 10, 8, 16), dtype=tf.float32,\n",
    "                        initializer=tf.random_normal_initializer(stddev=cfg.stddev))\n",
    "\n",
    "    # Eq.2, calc u_hat\n",
    "    # do tiling for input and W before matmul\n",
    "    # input => [batch_size, 1152, 10, 8, 1]\n",
    "    # W => [batch_size, 1152, 10, 8, 16]\n",
    "    input = tf.tile(input, [1, 1, 10, 1, 1])\n",
    "    W = tf.tile(W, [cfg.batch_size, 1, 1, 1, 1])\n",
    "    assert input.get_shape() == [cfg.batch_size, 1152, 10, 8, 1]\n",
    "\n",
    "    # in last 2 dims:\n",
    "    # [8, 16].T x [8, 1] => [16, 1] => [batch_size, 1152, 10, 16, 1]\n",
    "    # tf.scan, 3 iter, 1080ti, 128 batch size: 10min/epoch\n",
    "    # u_hat = tf.scan(lambda ac, x: tf.matmul(W, x, transpose_a=True), input, initializer=tf.zeros([1152, 10, 16, 1]))\n",
    "    # tf.tile, 3 iter, 1080ti, 128 batch size: 6min/epoch\n",
    "    u_hat = tf.matmul(W, input, transpose_a=True)\n",
    "    assert u_hat.get_shape() == [cfg.batch_size, 1152, 10, 16, 1]\n",
    "\n",
    "    # In forward, u_hat_stopped = u_hat; in backward, no gradient passed back from u_hat_stopped to u_hat\n",
    "    u_hat_stopped = tf.stop_gradient(u_hat, name='stop_gradient')\n",
    "\n",
    "    # line 3,for r iterations do\n",
    "    for r_iter in range(cfg.iter_routing):\n",
    "        with tf.variable_scope('iter_' + str(r_iter)):\n",
    "            # line 4:\n",
    "            # => [batch_size, 1152, 10, 1, 1]\n",
    "            c_IJ = tf.nn.softmax(b_IJ, dim=2)\n",
    "\n",
    "            # At last iteration, use `u_hat` in order to receive gradients from the following graph\n",
    "            if r_iter == cfg.iter_routing - 1:\n",
    "                # line 5:\n",
    "                # weighting u_hat with c_IJ, element-wise in the last two dims\n",
    "                # => [batch_size, 1152, 10, 16, 1]\n",
    "                s_J = tf.multiply(c_IJ, u_hat)\n",
    "                # then sum in the second dim, resulting in [batch_size, 1, 10, 16, 1]\n",
    "                s_J = tf.reduce_sum(s_J, axis=1, keep_dims=True)\n",
    "                assert s_J.get_shape() == [cfg.batch_size, 1, 10, 16, 1]\n",
    "\n",
    "                # line 6:\n",
    "                # squash using Eq.1,\n",
    "                v_J = squash(s_J)\n",
    "                assert v_J.get_shape() == [cfg.batch_size, 1, 10, 16, 1]\n",
    "            elif r_iter < cfg.iter_routing - 1:  # Inner iterations, do not apply backpropagation\n",
    "                s_J = tf.multiply(c_IJ, u_hat_stopped)\n",
    "                s_J = tf.reduce_sum(s_J, axis=1, keep_dims=True)\n",
    "                v_J = squash(s_J)\n",
    "\n",
    "                # line 7:\n",
    "                # reshape & tile v_j from [batch_size ,1, 10, 16, 1] to [batch_size, 1152, 10, 16, 1]\n",
    "                # then matmul in the last tow dim: [16, 1].T x [16, 1] => [1, 1], reduce mean in the\n",
    "                # batch_size dim, resulting in [1, 1152, 10, 1, 1]\n",
    "                v_J_tiled = tf.tile(v_J, [1, 1152, 1, 1, 1])\n",
    "                u_produce_v = tf.matmul(u_hat_stopped, v_J_tiled, transpose_a=True)\n",
    "                assert u_produce_v.get_shape() == [cfg.batch_size, 1152, 10, 1, 1]\n",
    "\n",
    "                # b_IJ += tf.reduce_sum(u_produce_v, axis=0, keep_dims=True)\n",
    "                b_IJ += u_produce_v\n",
    "\n",
    "    return(v_J)\n",
    "\n",
    "\n",
    "def squash(vector):\n",
    "    '''Squashing function corresponding to Eq. 1\n",
    "    Args:\n",
    "        vector: A tensor with shape [batch_size, 1, num_caps, vec_len, 1] or [batch_size, num_caps, vec_len, 1].\n",
    "    Returns:\n",
    "        A tensor with the same shape as vector but squashed in 'vec_len' dimension.\n",
    "    '''\n",
    "    vec_squared_norm = tf.reduce_sum(tf.square(vector), -2, keep_dims=True)\n",
    "    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + epsilon)\n",
    "    vec_squashed = scalar_factor * vector  # element-wise\n",
    "    return(vec_squashed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-9\n",
    "\n",
    "\n",
    "class CapsNet(object):\n",
    "    def __init__(self, is_training=True):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            if is_training:\n",
    "                self.X, self.labels = get_batch_data(cfg.dataset, cfg.batch_size, cfg.num_threads)\n",
    "                self.Y = tf.one_hot(self.labels, depth=10, axis=1, dtype=tf.float32)\n",
    "\n",
    "                self.build_arch()\n",
    "                self.loss()\n",
    "                self._summary()\n",
    "\n",
    "                # t_vars = tf.trainable_variables()\n",
    "                self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "                self.optimizer = tf.train.AdamOptimizer()\n",
    "                self.train_op = self.optimizer.minimize(self.total_loss, global_step=self.global_step)  # var_list=t_vars)\n",
    "            else:\n",
    "                self.X = tf.placeholder(tf.float32, shape=(cfg.batch_size, 28, 28, 1))\n",
    "                self.labels = tf.placeholder(tf.int32, shape=(cfg.batch_size, ))\n",
    "                self.Y = tf.reshape(self.labels, shape=(cfg.batch_size, 10, 1))\n",
    "                self.build_arch()\n",
    "\n",
    "        tf.logging.info('Seting up the main structure')\n",
    "\n",
    "    def build_arch(self):\n",
    "        with tf.variable_scope('Conv1_layer'):\n",
    "            # Conv1, [batch_size, 20, 20, 256]\n",
    "            conv1 = tf.contrib.layers.conv2d(self.X, num_outputs=256,\n",
    "                                             kernel_size=9, stride=1,\n",
    "                                             padding='VALID')\n",
    "            assert conv1.get_shape() == [cfg.batch_size, 20, 20, 256]\n",
    "\n",
    "        # Primary Capsules layer, return [batch_size, 1152, 8, 1]\n",
    "        with tf.variable_scope('PrimaryCaps_layer'):\n",
    "            primaryCaps = CapsLayer(num_outputs=32, vec_len=8, with_routing=False, layer_type='CONV')\n",
    "            caps1 = primaryCaps(conv1, kernel_size=9, stride=2)\n",
    "            assert caps1.get_shape() == [cfg.batch_size, 1152, 8, 1]\n",
    "\n",
    "        # DigitCaps layer, return [batch_size, 10, 16, 1]\n",
    "        with tf.variable_scope('DigitCaps_layer'):\n",
    "            digitCaps = CapsLayer(num_outputs=10, vec_len=16, with_routing=True, layer_type='FC')\n",
    "            self.caps2 = digitCaps(caps1)\n",
    "\n",
    "        # Decoder structure in Fig. 2\n",
    "        # 1. Do masking, how:\n",
    "        with tf.variable_scope('Masking'):\n",
    "            # a). calc ||v_c||, then do softmax(||v_c||)\n",
    "            # [batch_size, 10, 16, 1] => [batch_size, 10, 1, 1]\n",
    "            self.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2),\n",
    "                                                  axis=2, keep_dims=True) + epsilon)\n",
    "            self.softmax_v = tf.nn.softmax(self.v_length, dim=1)\n",
    "            assert self.softmax_v.get_shape() == [cfg.batch_size, 10, 1, 1]\n",
    "\n",
    "            # b). pick out the index of max softmax val of the 10 caps\n",
    "            # [batch_size, 10, 1, 1] => [batch_size] (index)\n",
    "            self.argmax_idx = tf.to_int32(tf.argmax(self.softmax_v, axis=1))\n",
    "            assert self.argmax_idx.get_shape() == [cfg.batch_size, 1, 1]\n",
    "            self.argmax_idx = tf.reshape(self.argmax_idx, shape=(cfg.batch_size, ))\n",
    "\n",
    "            # Method 1.\n",
    "            if not cfg.mask_with_y:\n",
    "                # c). indexing\n",
    "                # It's not easy to understand the indexing process with argmax_idx\n",
    "                # as we are 3-dim animal\n",
    "                masked_v = []\n",
    "                for batch_size in range(cfg.batch_size):\n",
    "                    v = self.caps2[batch_size][self.argmax_idx[batch_size], :]\n",
    "                    masked_v.append(tf.reshape(v, shape=(1, 1, 16, 1)))\n",
    "\n",
    "                self.masked_v = tf.concat(masked_v, axis=0)\n",
    "                assert self.masked_v.get_shape() == [cfg.batch_size, 1, 16, 1]\n",
    "            # Method 2. masking with true label, default mode\n",
    "            else:\n",
    "                # self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)\n",
    "                self.masked_v = tf.multiply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)))\n",
    "                self.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2), axis=2, keep_dims=True) + epsilon)\n",
    "\n",
    "        # 2. Reconstructe the MNIST images with 3 FC layers\n",
    "        # [batch_size, 1, 16, 1] => [batch_size, 16] => [batch_size, 512]\n",
    "        with tf.variable_scope('Decoder'):\n",
    "            vector_j = tf.reshape(self.masked_v, shape=(cfg.batch_size, -1))\n",
    "            fc1 = tf.contrib.layers.fully_connected(vector_j, num_outputs=512)\n",
    "            assert fc1.get_shape() == [cfg.batch_size, 512]\n",
    "            fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=1024)\n",
    "            assert fc2.get_shape() == [cfg.batch_size, 1024]\n",
    "            self.decoded = tf.contrib.layers.fully_connected(fc2, num_outputs=784, activation_fn=tf.sigmoid)\n",
    "\n",
    "    def loss(self):\n",
    "        # 1. The margin loss\n",
    "\n",
    "        # [batch_size, 10, 1, 1]\n",
    "        # max_l = max(0, m_plus-||v_c||)^2\n",
    "        max_l = tf.square(tf.maximum(0., cfg.m_plus - self.v_length))\n",
    "        # max_r = max(0, ||v_c||-m_minus)^2\n",
    "        max_r = tf.square(tf.maximum(0., self.v_length - cfg.m_minus))\n",
    "        assert max_l.get_shape() == [cfg.batch_size, 10, 1, 1]\n",
    "\n",
    "        # reshape: [batch_size, 10, 1, 1] => [batch_size, 10]\n",
    "        max_l = tf.reshape(max_l, shape=(cfg.batch_size, -1))\n",
    "        max_r = tf.reshape(max_r, shape=(cfg.batch_size, -1))\n",
    "\n",
    "        # calc T_c: [batch_size, 10]\n",
    "        # T_c = Y, is my understanding correct? Try it.\n",
    "        T_c = self.Y\n",
    "        # [batch_size, 10], element-wise multiply\n",
    "        L_c = T_c * max_l + cfg.lambda_val * (1 - T_c) * max_r\n",
    "\n",
    "        self.margin_loss = tf.reduce_mean(tf.reduce_sum(L_c, axis=1))\n",
    "\n",
    "        # 2. The reconstruction loss\n",
    "        orgin = tf.reshape(self.X, shape=(cfg.batch_size, -1))\n",
    "        squared = tf.square(self.decoded - orgin)\n",
    "        self.reconstruction_err = tf.reduce_mean(squared)\n",
    "\n",
    "        # 3. Total loss\n",
    "        # The paper uses sum of squared error as reconstruction error, but we\n",
    "        # have used reduce_mean in `# 2 The reconstruction loss` to calculate\n",
    "        # mean squared error. In order to keep in line with the paper,the\n",
    "        # regularization scale should be 0.0005*784=0.392\n",
    "        self.total_loss = self.margin_loss + cfg.regularization_scale * self.reconstruction_err\n",
    "\n",
    "    # Summary\n",
    "    def _summary(self):\n",
    "        train_summary = []\n",
    "        train_summary.append(tf.summary.scalar('train/margin_loss', self.margin_loss))\n",
    "        train_summary.append(tf.summary.scalar('train/reconstruction_loss', self.reconstruction_err))\n",
    "        train_summary.append(tf.summary.scalar('train/total_loss', self.total_loss))\n",
    "        recon_img = tf.reshape(self.decoded, shape=(cfg.batch_size, 28, 28, 1))\n",
    "        train_summary.append(tf.summary.image('reconstruction_img', recon_img))\n",
    "        self.train_summary = tf.summary.merge(train_summary)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.to_int32(self.labels), self.argmax_idx)\n",
    "        self.accuracy = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: Loading Graph...\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/mnist/train-images-idx3-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5adad149bce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5adad149bce1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' Loading Graph...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mnum_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCapsNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' Graph loaded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d55d7324b6c0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, is_training)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6975b0cb231b>\u001b[0m in \u001b[0;36mget_batch_data\u001b[0;34m(dataset, batch_size, num_threads)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mnist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tr_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_val_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fashion-mnist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tr_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_val_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fashion_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6975b0cb231b>\u001b[0m in \u001b[0;36mload_mnist\u001b[0;34m(batch_size, is_training)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train-images-idx3-ubyte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/mnist/train-images-idx3-ubyte'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def save_to():\n",
    "    if not os.path.exists(cfg.results):\n",
    "        os.mkdir(cfg.results)\n",
    "    if cfg.is_training:\n",
    "        loss = cfg.results + '/loss.csv'\n",
    "        train_acc = cfg.results + '/train_acc.csv'\n",
    "        val_acc = cfg.results + '/val_acc.csv'\n",
    "\n",
    "        if os.path.exists(val_acc):\n",
    "            os.remove(val_acc)\n",
    "        if os.path.exists(loss):\n",
    "            os.remove(loss)\n",
    "        if os.path.exists(train_acc):\n",
    "            os.remove(train_acc)\n",
    "\n",
    "        fd_train_acc = open(train_acc, 'w')\n",
    "        fd_train_acc.write('step,train_acc\\n')\n",
    "        fd_loss = open(loss, 'w')\n",
    "        fd_loss.write('step,loss\\n')\n",
    "        fd_val_acc = open(val_acc, 'w')\n",
    "        fd_val_acc.write('step,val_acc\\n')\n",
    "        return(fd_train_acc, fd_loss, fd_val_acc)\n",
    "    else:\n",
    "        test_acc = cfg.results + '/test_acc.csv'\n",
    "        if os.path.exists(test_acc):\n",
    "            os.remove(test_acc)\n",
    "        fd_test_acc = open(test_acc, 'w')\n",
    "        fd_test_acc.write('test_acc\\n')\n",
    "        return(fd_test_acc)\n",
    "\n",
    "\n",
    "def train(model, supervisor, num_label):\n",
    "    trX, trY, num_tr_batch, valX, valY, num_val_batch = load_data(cfg.dataset, cfg.batch_size, is_training=True)\n",
    "    Y = valY[:num_val_batch * cfg.batch_size].reshape((-1, 1))\n",
    "\n",
    "    fd_train_acc, fd_loss, fd_val_acc = save_to()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with supervisor.managed_session(config=config) as sess:\n",
    "        print(\"\\nNote: all of results will be saved to directory: \" + cfg.results)\n",
    "        for epoch in range(cfg.epoch):\n",
    "            print('Training for epoch ' + str(epoch) + '/' + str(cfg.epoch) + ':')\n",
    "            if supervisor.should_stop():\n",
    "                print('supervisor stoped!')\n",
    "                break\n",
    "            # for step in tqdm(range(num_tr_batch), total=num_tr_batch, ncols=70, leave=False, unit='b'):\n",
    "            for step in range(num_tr_batch):\n",
    "                start = step * cfg.batch_size\n",
    "                end = start + cfg.batch_size\n",
    "                global_step = epoch * num_tr_batch + step\n",
    "\n",
    "                if global_step % cfg.train_sum_freq == 0:\n",
    "                    _, loss, train_acc, summary_str = sess.run([model.train_op, model.total_loss, model.accuracy, model.train_summary])\n",
    "                    assert not np.isnan(loss), 'Something wrong! loss is nan...'\n",
    "                    supervisor.summary_writer.add_summary(summary_str, global_step)\n",
    "\n",
    "                    fd_loss.write(str(global_step) + ',' + str(loss) + \"\\n\")\n",
    "                    fd_loss.flush()\n",
    "                    fd_train_acc.write(str(global_step) + ',' + str(train_acc / cfg.batch_size) + \"\\n\")\n",
    "                    fd_train_acc.flush()\n",
    "                else:\n",
    "                    sess.run(model.train_op)\n",
    "\n",
    "                if cfg.val_sum_freq != 0 and (global_step) % cfg.val_sum_freq == 0:\n",
    "                    val_acc = 0\n",
    "                    for i in range(num_val_batch):\n",
    "                        start = i * cfg.batch_size\n",
    "                        end = start + cfg.batch_size\n",
    "                        acc = sess.run(model.accuracy, {model.X: valX[start:end], model.labels: valY[start:end]})\n",
    "                        val_acc += acc\n",
    "                    val_acc = val_acc / (cfg.batch_size * num_val_batch)\n",
    "                    fd_val_acc.write(str(global_step) + ',' + str(val_acc) + '\\n')\n",
    "                    fd_val_acc.flush()\n",
    "\n",
    "            if (epoch + 1) % cfg.save_freq == 0:\n",
    "                supervisor.saver.save(sess, cfg.logdir + '/model_epoch_%04d_step_%02d' % (epoch, global_step))\n",
    "\n",
    "        fd_val_acc.close()\n",
    "        fd_train_acc.close()\n",
    "        fd_loss.close()\n",
    "\n",
    "\n",
    "def evaluation(model, supervisor, num_label):\n",
    "    teX, teY, num_te_batch = load_data(cfg.dataset, cfg.batch_size, is_training=False)\n",
    "    fd_test_acc = save_to()\n",
    "    with supervisor.managed_session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        supervisor.saver.restore(sess, tf.train.latest_checkpoint(cfg.logdir))\n",
    "        tf.logging.info('Model restored!')\n",
    "\n",
    "        test_acc = 0\n",
    "        # for i in tqdm(range(num_te_batch), total=num_te_batch, ncols=70, leave=False, unit='b'):\n",
    "        for i in range(num_te_batch):\n",
    "            start = i * cfg.batch_size\n",
    "            end = start + cfg.batch_size\n",
    "            acc = sess.run(model.accuracy, {model.X: teX[start:end], model.labels: teY[start:end]})\n",
    "            test_acc += acc\n",
    "        test_acc = test_acc / (cfg.batch_size * num_te_batch)\n",
    "        fd_test_acc.write(str(test_acc))\n",
    "        fd_test_acc.close()\n",
    "        print('Test accuracy has been saved to ' + cfg.results + '/test_accuracy.txt')\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    tf.logging.info(' Loading Graph...')\n",
    "    num_label = 10\n",
    "    model = CapsNet()\n",
    "    tf.logging.info(' Graph loaded')\n",
    "\n",
    "    sv = tf.train.Supervisor(graph=model.graph, logdir=cfg.logdir, save_model_secs=0)\n",
    "\n",
    "    if cfg.is_training:\n",
    "        tf.logging.info(' Start training...')\n",
    "        train(model, sv, num_label)\n",
    "        tf.logging.info('Training done')\n",
    "    else:\n",
    "        evaluation(model, sv, num_label)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
