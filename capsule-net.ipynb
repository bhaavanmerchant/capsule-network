{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tqdm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d63c60e4cd33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named tqdm"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import cfg\n",
    "from utils import load_data\n",
    "from capsNet import CapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to():\n",
    "    if not os.path.exists(cfg.results):\n",
    "        os.mkdir(cfg.results)\n",
    "    if cfg.is_training:\n",
    "        loss = cfg.results + '/loss.csv'\n",
    "        train_acc = cfg.results + '/train_acc.csv'\n",
    "        val_acc = cfg.results + '/val_acc.csv'\n",
    "\n",
    "        if os.path.exists(val_acc):\n",
    "            os.remove(val_acc)\n",
    "        if os.path.exists(loss):\n",
    "            os.remove(loss)\n",
    "        if os.path.exists(train_acc):\n",
    "            os.remove(train_acc)\n",
    "\n",
    "        fd_train_acc = open(train_acc, 'w')\n",
    "        fd_train_acc.write('step,train_acc\\n')\n",
    "        fd_loss = open(loss, 'w')\n",
    "        fd_loss.write('step,loss\\n')\n",
    "        fd_val_acc = open(val_acc, 'w')\n",
    "        fd_val_acc.write('step,val_acc\\n')\n",
    "        return(fd_train_acc, fd_loss, fd_val_acc)\n",
    "    else:\n",
    "        test_acc = cfg.results + '/test_acc.csv'\n",
    "        if os.path.exists(test_acc):\n",
    "            os.remove(test_acc)\n",
    "        fd_test_acc = open(test_acc, 'w')\n",
    "        fd_test_acc.write('test_acc\\n')\n",
    "        return(fd_test_acc)\n",
    "\n",
    "\n",
    "def train(model, supervisor, num_label):\n",
    "    trX, trY, num_tr_batch, valX, valY, num_val_batch = load_data(cfg.dataset, cfg.batch_size, is_training=True)\n",
    "    Y = valY[:num_val_batch * cfg.batch_size].reshape((-1, 1))\n",
    "\n",
    "    fd_train_acc, fd_loss, fd_val_acc = save_to()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with supervisor.managed_session(config=config) as sess:\n",
    "        print(\"\\nNote: all of results will be saved to directory: \" + cfg.results)\n",
    "        for epoch in range(cfg.epoch):\n",
    "            print('Training for epoch ' + str(epoch) + '/' + str(cfg.epoch) + ':')\n",
    "            if supervisor.should_stop():\n",
    "                print('supervisor stoped!')\n",
    "                break\n",
    "            for step in tqdm(range(num_tr_batch), total=num_tr_batch, ncols=70, leave=False, unit='b'):\n",
    "                start = step * cfg.batch_size\n",
    "                end = start + cfg.batch_size\n",
    "                global_step = epoch * num_tr_batch + step\n",
    "\n",
    "                if global_step % cfg.train_sum_freq == 0:\n",
    "                    _, loss, train_acc, summary_str = sess.run([model.train_op, model.total_loss, model.accuracy, model.train_summary])\n",
    "                    assert not np.isnan(loss), 'Something wrong! loss is nan...'\n",
    "                    supervisor.summary_writer.add_summary(summary_str, global_step)\n",
    "\n",
    "                    fd_loss.write(str(global_step) + ',' + str(loss) + \"\\n\")\n",
    "                    fd_loss.flush()\n",
    "                    fd_train_acc.write(str(global_step) + ',' + str(train_acc / cfg.batch_size) + \"\\n\")\n",
    "                    fd_train_acc.flush()\n",
    "                else:\n",
    "                    sess.run(model.train_op)\n",
    "\n",
    "                if cfg.val_sum_freq != 0 and (global_step) % cfg.val_sum_freq == 0:\n",
    "                    val_acc = 0\n",
    "                    for i in range(num_val_batch):\n",
    "                        start = i * cfg.batch_size\n",
    "                        end = start + cfg.batch_size\n",
    "                        acc = sess.run(model.accuracy, {model.X: valX[start:end], model.labels: valY[start:end]})\n",
    "                        val_acc += acc\n",
    "                    val_acc = val_acc / (cfg.batch_size * num_val_batch)\n",
    "                    fd_val_acc.write(str(global_step) + ',' + str(val_acc) + '\\n')\n",
    "                    fd_val_acc.flush()\n",
    "\n",
    "            if (epoch + 1) % cfg.save_freq == 0:\n",
    "                supervisor.saver.save(sess, cfg.logdir + '/model_epoch_%04d_step_%02d' % (epoch, global_step))\n",
    "\n",
    "        fd_val_acc.close()\n",
    "        fd_train_acc.close()\n",
    "        fd_loss.close()\n",
    "\n",
    "\n",
    "def evaluation(model, supervisor, num_label):\n",
    "    teX, teY, num_te_batch = load_data(cfg.dataset, cfg.batch_size, is_training=False)\n",
    "    fd_test_acc = save_to()\n",
    "    with supervisor.managed_session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        supervisor.saver.restore(sess, tf.train.latest_checkpoint(cfg.logdir))\n",
    "        tf.logging.info('Model restored!')\n",
    "\n",
    "        test_acc = 0\n",
    "        for i in tqdm(range(num_te_batch), total=num_te_batch, ncols=70, leave=False, unit='b'):\n",
    "            start = i * cfg.batch_size\n",
    "            end = start + cfg.batch_size\n",
    "            acc = sess.run(model.accuracy, {model.X: teX[start:end], model.labels: teY[start:end]})\n",
    "            test_acc += acc\n",
    "        test_acc = test_acc / (cfg.batch_size * num_te_batch)\n",
    "        fd_test_acc.write(str(test_acc))\n",
    "        fd_test_acc.close()\n",
    "        print('Test accuracy has been saved to ' + cfg.results + '/test_accuracy.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.info(' Loading Graph...')\n",
    "num_label = 10\n",
    "model = CapsNet()\n",
    "tf.logging.info(' Graph loaded')\n",
    "\n",
    "sv = tf.train.Supervisor(graph=model.graph, logdir=cfg.logdir, save_model_secs=0)\n",
    "\n",
    "if cfg.is_training:\n",
    "    tf.logging.info(' Start training...')\n",
    "    train(model, sv, num_label)\n",
    "    tf.logging.info('Training done')\n",
    "else:\n",
    "    evaluation(model, sv, num_label)\n",
    "\n",
    "tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
